{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystk2_gymnasium.stk_wrappers import ConstantSizedObservations, PolarObservations, DiscreteActionsWrapper\n",
    "from pystk2_gymnasium.wrappers import FlattenerWrapper\n",
    "from stk_actor.wrappers import PreprocessObservationWrapper\n",
    "\n",
    "import ipyparallel\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_agent(args_list):\n",
    "\n",
    "    from stk_actor.agent import UnifiedSACPolicy\n",
    "    from stk_actor.wrappers import PreprocessObservationWrapper\n",
    "    from pystk2_gymnasium.stk_wrappers import ConstantSizedObservations, PolarObservations, DiscreteActionsWrapper\n",
    "    from pystk2_gymnasium.wrappers import FlattenerWrapper\n",
    "    from pystk2_gymnasium import MonoAgentWrapperAdapter\n",
    "    from stk_actor.wrappers import PreprocessObservationWrapper\n",
    "    from pystk2_gymnasium import AgentSpec\n",
    "    from bbrl.agents import Agents\n",
    "    from bbrl.agents.gymnasium import ParallelGymAgent, make_env\n",
    "    from bbrl.workspace import Workspace\n",
    "    from functools import partial\n",
    "    from stk_actor.actors import Actor, ArgmaxActor\n",
    "\n",
    "    agents = []\n",
    "    agents_spec = []\n",
    "    player_names = []\n",
    "\n",
    "    def get_action(workspace: Workspace, t: int):\n",
    "        name = \"action\"\n",
    "\n",
    "        if name in workspace.variables:\n",
    "            # Action is a tensor\n",
    "            action = workspace.get(name, t)\n",
    "        else:\n",
    "            # Action is a dictionary\n",
    "            action = {}\n",
    "            prefix = f\"{name}/\"\n",
    "            len_prefix = len(prefix)\n",
    "            for varname in workspace.variables:\n",
    "                if not varname.startswith(prefix):\n",
    "                    continue\n",
    "                keys = varname[len_prefix:].split(\"/\")\n",
    "                current = action\n",
    "                for key in keys[:-1]:\n",
    "                    current = current.setdefault(key, {})\n",
    "                current[keys[-1]] = workspace.get(varname, t)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    def dict_slice(k: int, object):\n",
    "        if isinstance(object, dict):\n",
    "            return {key: dict_slice(k, value) for key, value in object.items()}\n",
    "        return object[k]\n",
    "\n",
    "    def is_integer(n):\n",
    "        try:\n",
    "            float(n)\n",
    "        except ValueError:\n",
    "            return False\n",
    "        else:\n",
    "            return float(n).is_integer()\n",
    "\n",
    "    def wrapper_func(state_items, state_karts, state_paths, norm, agent_name, env):\n",
    "        return PreprocessObservationWrapper(\n",
    "            FlattenerWrapper(\n",
    "                DiscreteActionsWrapper(\n",
    "                    PolarObservations(\n",
    "                        ConstantSizedObservations(\n",
    "                            env,\n",
    "                            state_items = state_items,\n",
    "                            state_karts = state_karts, \n",
    "                            state_paths = state_paths,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ), \n",
    "            ret_dict=True, \n",
    "            norm=norm,\n",
    "            agent_name=agent_name\n",
    "        )\n",
    "    \n",
    "    interactive=False\n",
    "\n",
    "    wrapper_factories = {}\n",
    "    for agent_ix, (track, agent_name, statedict_path, net_arch, activation_fn, mean, std, state_items, state_karts, state_paths) in enumerate(args_list):\n",
    "        wrapper_factories[str(agent_ix)]=partial(wrapper_func, state_items, state_karts, state_paths, (std is not None and mean is not None), agent_name)\n",
    "        agents_spec.append(AgentSpec(name=agent_name))\n",
    "        player_names.append(agent_name)\n",
    "        \n",
    "    n_agents = len(args_list)\n",
    "\n",
    "    env = make_env(\n",
    "        \"supertuxkart/multi-full-v0\",\n",
    "        render_mode=None,\n",
    "        agents=agents_spec,\n",
    "        num_kart=n_agents,\n",
    "        track=track,\n",
    "        wrappers=[\n",
    "            partial(\n",
    "                    MonoAgentWrapperAdapter,\n",
    "                    keep_original=interactive,\n",
    "                    wrapper_factories=wrapper_factories,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for agent_ix, (track, agent_name, statedict_path, net_arch, activation_fn, mean, std, state_items, state_karts, state_paths) in enumerate(args_list):\n",
    "\n",
    "        actor = Actor(\n",
    "            env.observation_space[str(agent_ix)], env.action_space[str(agent_ix)],\n",
    "            net_arch=net_arch, \n",
    "            activation_fn=activation_fn,\n",
    "            state_dict_path=statedict_path,\n",
    "        )\n",
    "        agent = Agents(actor, ArgmaxActor())\n",
    "        agents.append(agent)\n",
    "\n",
    "    for agent in agents:\n",
    "        agent.eval()\n",
    "\n",
    "    workspaces = [Workspace() for _ in range(n_agents)]\n",
    "    print(\"Starting a race\")\n",
    "\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "    choice = \"\"\n",
    "\n",
    "    # List possible keys\n",
    "    keys = []\n",
    "    for key, item in obs.items():\n",
    "        for subkey in item.keys():\n",
    "            keys.append((key, subkey))\n",
    "    keys.sort()\n",
    "\n",
    "    t = 0\n",
    "    while not done:\n",
    "\n",
    "        actions = {}\n",
    "        for ix in range(n_agents):\n",
    "            key = str(ix)\n",
    "            obs_agent = ParallelGymAgent._format_frame(obs[key])\n",
    "            for var_key, var_value in obs_agent.items():\n",
    "                workspaces[ix].set(f\"env/{var_key}\", t, var_value)\n",
    "            agents[ix](workspaces[ix], t=t)\n",
    "            action = get_action(workspaces[ix], t=t)\n",
    "            if isinstance(action, dict):\n",
    "                action = dict_slice(0, action)\n",
    "            else:\n",
    "                action = action[0]\n",
    "\n",
    "            actions[key] = action\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(actions)\n",
    "        done = terminated or truncated\n",
    "        t += 1\n",
    "\n",
    "    records = []\n",
    "    rewards = info[\"reward\"]\n",
    "    for ix in range(n_agents):\n",
    "        key = str(ix)\n",
    "        print(  # noqa: T201\n",
    "            f\"{rewards[key]}\\t{info['infos'][key]['position']}\"\n",
    "            f\"\\t{ix}\\t{player_names[ix]}\"\n",
    "        )\n",
    "        records.append({\n",
    "            'agent_name': player_names[ix],\n",
    "            'reward' : rewards[str(ix)],\n",
    "            'position' : info['infos'][str(ix)]['position'],\n",
    "            'track' : track,\n",
    "        })\n",
    "\n",
    "    return records\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'stk_actor/trained_agents/'\n",
    "\n",
    "agents = [\n",
    "    [\n",
    "        'normed_behavioral_cloning_num5',\n",
    "        path+'normed_behavioral_cloning_num5/statedict',\n",
    "        path+'normed_behavioral_cloning_num5/buffer_mean',\n",
    "        path+'normed_behavioral_cloning_num5/buffer_std',\n",
    "        5, 5 ,5,\n",
    "    ],\n",
    "    [\n",
    "        'normed_behavioral_cloning_num10',\n",
    "        path+'normed_behavioral_cloning_num10/statedict',\n",
    "        path+'normed_behavioral_cloning_num10/buffer_mean',\n",
    "        path+'normed_behavioral_cloning_num10/buffer_std',\n",
    "        10,10,10,\n",
    "    ],\n",
    "    [\n",
    "        'non_normed_behavioral_cloning_num5',\n",
    "        path+'non_normed_behavioral_cloning_num5/statedict',\n",
    "        None,\n",
    "        None,\n",
    "        5, 5 ,5,\n",
    "    ],\n",
    "    [\n",
    "        'non_normed_behavioral_cloning_num10',\n",
    "        path+'non_normed_behavioral_cloning_num10/statedict',\n",
    "        None,\n",
    "        None,\n",
    "        10,10,10,\n",
    "    ],\n",
    "    [\n",
    "        'normed_a2c_num5_no_init',\n",
    "        path+'normed_a2c_num5_no_init/statedict',\n",
    "        path+'normed_a2c_num5_no_init/buffer_mean',\n",
    "        path+'normed_a2c_num5_no_init/buffer_std',\n",
    "        5,5,5,\n",
    "    ],\n",
    "    [\n",
    "        'normed_ppo_num5_no_init',\n",
    "        path+'normed_ppo_num5_no_init/statedict',\n",
    "        path+'normed_ppo_num5_no_init/buffer_mean',\n",
    "        path+'normed_ppo_num5_no_init/buffer_std',\n",
    "        5,5,5,\n",
    "    ],\n",
    "    [\n",
    "        'normed_a2c_num5_best',\n",
    "        path+'normed_a2c_num5_best/statedict',\n",
    "        path+'normed_a2c_num5_best/buffer_mean',\n",
    "        path+'normed_a2c_num5_best/buffer_std',\n",
    "        5,5,5,\n",
    "    ],\n",
    "    [\n",
    "        'normed_ppo_num5_best',\n",
    "        path+'normed_ppo_num5_best/statedict',\n",
    "        path+'normed_ppo_num5_best/buffer_mean',\n",
    "        path+'normed_ppo_num5_best/buffer_std',\n",
    "        5,5,5,\n",
    "    ],\n",
    "]\n",
    "\n",
    "net_arch=[1024,1024,1024]\n",
    "activation_fn=torch.nn.Tanh\n",
    "\n",
    "tracks = [\n",
    "    'black_forest','olivermath','minigolf','gran_paradiso_island', 'candela_city', 'mines', 'snowmountain', 'abyss', 'cornfield_crossing', 'hacienda','lighthouse', 'snowtuxpeak', 'zengarden', 'fortmagma','ravenbridge_mansion', 'cocoa_temple', 'sandtrack', 'scotland', 'stk_enterprise', 'volcano_island','xr591',       \n",
    "]\n",
    "\n",
    "args_list_list = []\n",
    "\n",
    "for track in tracks:\n",
    "\n",
    "    args_list = []\n",
    "\n",
    "    for agent_name, statedict_path, mean_path, std_path, state_items, state_karts, state_paths in agents:\n",
    "        \n",
    "        mean, std = None, None\n",
    "        if mean_path is not None:   \n",
    "            mean = torch.load(mean_path, map_location='cpu', weights_only=True)\n",
    "        if std_path is not None:\n",
    "            std = torch.load(std_path, map_location='cpu', weights_only=True)\n",
    "\n",
    "        args_list.append(\n",
    "            (\n",
    "                track, agent_name, statedict_path, net_arch, activation_fn, mean, std, state_items, state_karts, state_paths,\n",
    "            )\n",
    "        )\n",
    "    args_list_list.append(args_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_run_episodes(args,):\n",
    "    client = ipyparallel.Client()\n",
    "    dview = client[:]\n",
    "\n",
    "    dview.push({'eval_agent': eval_agent})\n",
    "    results = dview.map(eval_agent, args, )\n",
    "\n",
    "    print('running:', len(args))\n",
    "    \n",
    "    records = []\n",
    "    for rec in tqdm.tqdm(results, total=len(args)):\n",
    "        records.extend(rec)\n",
    "\n",
    "    client.close()\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [16:50<00:00, 48.10s/it]   \n"
     ]
    }
   ],
   "source": [
    "records = parallel_run_episodes(args_list_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_name</th>\n",
       "      <th>reward</th>\n",
       "      <th>position</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>normed_ppo_num5_best</td>\n",
       "      <td>18.718530</td>\n",
       "      <td>1</td>\n",
       "      <td>snowmountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>normed_behavioral_cloning_num10</td>\n",
       "      <td>18.718872</td>\n",
       "      <td>1</td>\n",
       "      <td>abyss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>normed_a2c_num5_best</td>\n",
       "      <td>18.717261</td>\n",
       "      <td>1</td>\n",
       "      <td>ravenbridge_mansion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>normed_behavioral_cloning_num10</td>\n",
       "      <td>18.712756</td>\n",
       "      <td>1</td>\n",
       "      <td>zengarden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>normed_ppo_num5_best</td>\n",
       "      <td>18.697437</td>\n",
       "      <td>1</td>\n",
       "      <td>minigolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>normed_ppo_num5_no_init</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>8</td>\n",
       "      <td>scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>non_normed_behavioral_cloning_num5</td>\n",
       "      <td>0.048630</td>\n",
       "      <td>8</td>\n",
       "      <td>sandtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>normed_a2c_num5_no_init</td>\n",
       "      <td>-0.100318</td>\n",
       "      <td>8</td>\n",
       "      <td>hacienda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>normed_a2c_num5_no_init</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>8</td>\n",
       "      <td>mines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>non_normed_behavioral_cloning_num10</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>8</td>\n",
       "      <td>lighthouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              agent_name     reward  position  \\\n",
       "55                  normed_ppo_num5_best  18.718530         1   \n",
       "57       normed_behavioral_cloning_num10  18.718872         1   \n",
       "118                 normed_a2c_num5_best  18.717261         1   \n",
       "97       normed_behavioral_cloning_num10  18.712756         1   \n",
       "23                  normed_ppo_num5_best  18.697437         1   \n",
       "..                                   ...        ...       ...   \n",
       "141              normed_ppo_num5_no_init  -0.099998         8   \n",
       "130   non_normed_behavioral_cloning_num5   0.048630         8   \n",
       "76               normed_a2c_num5_no_init  -0.100318         8   \n",
       "44               normed_a2c_num5_no_init  -0.099998         8   \n",
       "83   non_normed_behavioral_cloning_num10  -0.100000         8   \n",
       "\n",
       "                   track  \n",
       "55          snowmountain  \n",
       "57                 abyss  \n",
       "118  ravenbridge_mansion  \n",
       "97             zengarden  \n",
       "23              minigolf  \n",
       "..                   ...  \n",
       "141             scotland  \n",
       "130            sandtrack  \n",
       "76              hacienda  \n",
       "44                 mines  \n",
       "83            lighthouse  \n",
       "\n",
       "[168 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "df = df.sort_values('position')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_name</th>\n",
       "      <th>position_mean</th>\n",
       "      <th>position_std</th>\n",
       "      <th>reward_mean</th>\n",
       "      <th>reward_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non_normed_behavioral_cloning_num10</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>1.277753</td>\n",
       "      <td>0.548363</td>\n",
       "      <td>0.485289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_normed_behavioral_cloning_num5</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>1.396465</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.526661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normed_a2c_num5_best</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>1.376841</td>\n",
       "      <td>15.411088</td>\n",
       "      <td>5.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normed_a2c_num5_no_init</td>\n",
       "      <td>5.904762</td>\n",
       "      <td>1.230747</td>\n",
       "      <td>0.696442</td>\n",
       "      <td>0.477738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normed_behavioral_cloning_num10</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>1.749636</td>\n",
       "      <td>12.881247</td>\n",
       "      <td>6.777753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normed_behavioral_cloning_num5</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>1.419016</td>\n",
       "      <td>10.420558</td>\n",
       "      <td>7.314071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>normed_ppo_num5_best</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>1.587936</td>\n",
       "      <td>14.864902</td>\n",
       "      <td>6.634027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>normed_ppo_num5_no_init</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>1.277753</td>\n",
       "      <td>0.546978</td>\n",
       "      <td>0.493031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            agent_name  position_mean  position_std  \\\n",
       "0  non_normed_behavioral_cloning_num10       6.285714      1.277753   \n",
       "1   non_normed_behavioral_cloning_num5       6.380952      1.396465   \n",
       "2                 normed_a2c_num5_best       2.095238      1.376841   \n",
       "3              normed_a2c_num5_no_init       5.904762      1.230747   \n",
       "4      normed_behavioral_cloning_num10       3.285714      1.749636   \n",
       "5       normed_behavioral_cloning_num5       3.714286      1.419016   \n",
       "6                 normed_ppo_num5_best       2.047619      1.587936   \n",
       "7              normed_ppo_num5_no_init       6.285714      1.277753   \n",
       "\n",
       "   reward_mean  reward_std  \n",
       "0     0.548363    0.485289  \n",
       "1     0.519989    0.526661  \n",
       "2    15.411088    5.788502  \n",
       "3     0.696442    0.477738  \n",
       "4    12.881247    6.777753  \n",
       "5    10.420558    7.314071  \n",
       "6    14.864902    6.634027  \n",
       "7     0.546978    0.493031  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def std(x):\n",
    "    return x.std(ddof=0)\n",
    "\n",
    "\n",
    "df_grouped = df.groupby('agent_name', as_index=False)[['position', 'reward']].agg({'position':['mean',std],'reward':['mean', std]})\n",
    "df_grouped.columns = ['agent_name'] + [f\"{col[0]}_{col[1]}\" for col in df_grouped.columns[1:]]\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "agent_name & position_mean & position_std & reward_mean & reward_std \\\\\n",
      "\\midrule\n",
      "PPO+Normalization+Size5+InitBHC & 2.047619 & 1.587936 & 14.864902 & 6.634027 \\\\\n",
      "AC2+Normalization+Size5+InitBHC & 2.095238 & 1.376841 & 15.411088 & 5.788502 \\\\\n",
      "BHC+Normalization+Size10 & 3.285714 & 1.749636 & 12.881247 & 6.777753 \\\\\n",
      "BHC+Normalization+Size5 & 3.714286 & 1.419016 & 10.420558 & 7.314071 \\\\\n",
      "AC2+Normalization+Size5+NoInit & 5.904762 & 1.230747 & 0.696442 & 0.477738 \\\\\n",
      "BHC+Size5 & 6.285714 & 1.277753 & 0.548363 & 0.485289 \\\\\n",
      "PPO+Normalization+Size5+NoInit & 6.285714 & 1.277753 & 0.546978 & 0.493031 \\\\\n",
      "BHC+Size10 & 6.380952 & 1.396465 & 0.519989 & 0.526661 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "df_grouped.sort_values('position_mean').replace(\n",
    "    {\n",
    "        'normed_a2c_num5_best':'AC2+Normalization+Size5+InitBHC',\n",
    "        'normed_a2c_num5_no_init':'AC2+Normalization+Size5+NoInit',\n",
    "        'normed_behavioral_cloning_num10':'BHC+Normalization+Size10',\n",
    "        'normed_behavioral_cloning_num5':'BHC+Normalization+Size5',\n",
    "        'normed_ppo_num5_best':'PPO+Normalization+Size5+InitBHC',\n",
    "        'normed_ppo_num5_no_init':'PPO+Normalization+Size5+NoInit',\n",
    "        'non_normed_behavioral_cloning_num5':'BHC+Size10',\n",
    "        'non_normed_behavioral_cloning_num10':'BHC+Size5',\n",
    "    }\n",
    ").to_latex(index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
