{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154, [5, 2, 2, 2, 2, 2, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "from pystk2_gymnasium import AgentSpec\n",
    "from stk_actor.replay_buffer import SACRolloutBuffer\n",
    "from stk_actor.wrappers import PreprocessObservationWrapper\n",
    "import torch\n",
    "\n",
    "class PolicyWrapper(torch.nn.Module):\n",
    "    def __init__(self, policy_stb, dropout):\n",
    "        super().__init__()\n",
    "        self.shared = policy_stb\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.shared.features_extractor(x)\n",
    "        x = self.shared.mlp_extractor.policy_net(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.shared.action_net(x)\n",
    "        return x\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    \"supertuxkart/flattened_multidiscrete-v0\", \n",
    "    n_envs=1, \n",
    "    wrapper_class=lambda x : (PreprocessObservationWrapper(x)), \n",
    "    env_kwargs={\n",
    "        'render_mode':None, 'agent':AgentSpec(use_ai=False, name=\"walid\"), 'difficulty':0,#'track':'abyss', #'num_kart':2, 'difficulty':0\n",
    "    }\n",
    ")\n",
    "vec_env.close()\n",
    "\n",
    "policy_stb = PPO('MlpPolicy', vec_env, policy_kwargs = dict(\n",
    "    net_arch=[512,512,512,512],\n",
    "    activation_fn=torch.nn.SiLU,\n",
    ")).policy\n",
    "\n",
    "obs_dim = vec_env.observation_space.shape[0]\n",
    "action_dims = [space.n for space in vec_env.action_space]\n",
    "\n",
    "device = 'mps'\n",
    "policy = PolicyWrapper(\n",
    "    policy_stb, 0\n",
    ").to(device)\n",
    "\n",
    "obs_dim, action_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_26303/738810281.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n"
     ]
    }
   ],
   "source": [
    "import joblib, random\n",
    "from torch.optim import AdamW\n",
    "\n",
    "batch_size = 1024 * 8\n",
    "start_step_id = 18\n",
    "num_epochs = 1000\n",
    "device = 'mps'\n",
    "\n",
    "policy = policy.to(device)\n",
    "\n",
    "optimizer = AdamW(policy.parameters(), lr=2e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "buffer1 = joblib.load('all_tracks_buffer_steps_2mil')\n",
    "batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_26303/3006995897.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Training Loss: 0.0937\n",
      "Action 0 Accuracy: 99.25%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.15%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.25%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.56%\n",
      "----------------------------------------\n",
      "Epoch 2/1000\n",
      "Training Loss: 0.0844\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.17%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.26%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.14%\n",
      "----------------------------------------\n",
      "Epoch 3/1000\n",
      "Training Loss: 0.0920\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.67%\n",
      "----------------------------------------\n",
      "Epoch 4/1000\n",
      "Training Loss: 0.0943\n",
      "Action 0 Accuracy: 99.25%\n",
      "Action 1 Accuracy: 99.69%\n",
      "Action 2 Accuracy: 99.17%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.25%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.53%\n",
      "----------------------------------------\n",
      "Epoch 5/1000\n",
      "Training Loss: 0.0853\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.06%\n",
      "----------------------------------------\n",
      "Epoch 6/1000\n",
      "Training Loss: 0.0943\n",
      "Action 0 Accuracy: 99.25%\n",
      "Action 1 Accuracy: 99.69%\n",
      "Action 2 Accuracy: 99.17%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.26%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.58%\n",
      "----------------------------------------\n",
      "Epoch 7/1000\n",
      "Training Loss: 0.0806\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.38%\n",
      "----------------------------------------\n",
      "Epoch 8/1000\n",
      "Training Loss: 0.0880\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.21%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.94%\n",
      "----------------------------------------\n",
      "Epoch 9/1000\n",
      "Training Loss: 0.1012\n",
      "Action 0 Accuracy: 99.25%\n",
      "Action 1 Accuracy: 99.69%\n",
      "Action 2 Accuracy: 99.16%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.23%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.16%\n",
      "----------------------------------------\n",
      "Epoch 10/1000\n",
      "Training Loss: 0.0874\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.94%\n",
      "----------------------------------------\n",
      "Epoch 11/1000\n",
      "Training Loss: 0.0819\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.27%\n",
      "----------------------------------------\n",
      "Epoch 12/1000\n",
      "Training Loss: 0.0921\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.69%\n",
      "----------------------------------------\n",
      "Epoch 13/1000\n",
      "Training Loss: 0.0863\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.00%\n",
      "----------------------------------------\n",
      "Epoch 14/1000\n",
      "Training Loss: 0.0807\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.34%\n",
      "----------------------------------------\n",
      "Epoch 15/1000\n",
      "Training Loss: 0.0849\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.11%\n",
      "----------------------------------------\n",
      "Epoch 16/1000\n",
      "Training Loss: 0.0943\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.25%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.58%\n",
      "----------------------------------------\n",
      "Epoch 17/1000\n",
      "Training Loss: 0.0835\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.19%\n",
      "----------------------------------------\n",
      "Epoch 18/1000\n",
      "Training Loss: 0.0942\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.17%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.57%\n",
      "----------------------------------------\n",
      "Epoch 19/1000\n",
      "Training Loss: 0.0949\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.69%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.25%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.53%\n",
      "----------------------------------------\n",
      "Epoch 20/1000\n",
      "Training Loss: 0.0812\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.20%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.31%\n",
      "----------------------------------------\n",
      "Epoch 21/1000\n",
      "Training Loss: 0.0792\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.43%\n",
      "----------------------------------------\n",
      "Epoch 22/1000\n",
      "Training Loss: 0.0882\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.95%\n",
      "----------------------------------------\n",
      "Epoch 23/1000\n",
      "Training Loss: 0.0971\n",
      "Action 0 Accuracy: 99.25%\n",
      "Action 1 Accuracy: 99.69%\n",
      "Action 2 Accuracy: 99.17%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.26%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.43%\n",
      "----------------------------------------\n",
      "Epoch 24/1000\n",
      "Training Loss: 0.0780\n",
      "Action 0 Accuracy: 99.29%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.20%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.50%\n",
      "----------------------------------------\n",
      "Epoch 25/1000\n",
      "Training Loss: 0.0821\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.21%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.29%\n",
      "----------------------------------------\n",
      "Epoch 26/1000\n",
      "Training Loss: 0.0806\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.30%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.37%\n",
      "----------------------------------------\n",
      "Epoch 27/1000\n",
      "Training Loss: 0.0871\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.97%\n",
      "----------------------------------------\n",
      "Epoch 28/1000\n",
      "Training Loss: 0.0881\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.92%\n",
      "----------------------------------------\n",
      "Epoch 29/1000\n",
      "Training Loss: 0.0838\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.17%\n",
      "----------------------------------------\n",
      "Epoch 30/1000\n",
      "Training Loss: 0.0830\n",
      "Action 0 Accuracy: 99.29%\n",
      "Action 1 Accuracy: 99.72%\n",
      "Action 2 Accuracy: 99.20%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.22%\n",
      "----------------------------------------\n",
      "Epoch 31/1000\n",
      "Training Loss: 0.0777\n",
      "Action 0 Accuracy: 99.29%\n",
      "Action 1 Accuracy: 99.72%\n",
      "Action 2 Accuracy: 99.21%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.30%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.51%\n",
      "----------------------------------------\n",
      "Epoch 32/1000\n",
      "Training Loss: 0.0841\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.21%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.16%\n",
      "----------------------------------------\n",
      "Epoch 33/1000\n",
      "Training Loss: 0.0908\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.76%\n",
      "----------------------------------------\n",
      "Epoch 34/1000\n",
      "Training Loss: 0.0803\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.37%\n",
      "----------------------------------------\n",
      "Epoch 35/1000\n",
      "Training Loss: 0.0824\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.20%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.24%\n",
      "----------------------------------------\n",
      "Epoch 36/1000\n",
      "Training Loss: 0.0884\n",
      "Action 0 Accuracy: 99.27%\n",
      "Action 1 Accuracy: 99.71%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.28%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.92%\n",
      "----------------------------------------\n",
      "Epoch 37/1000\n",
      "Training Loss: 0.0794\n",
      "Action 0 Accuracy: 99.28%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.21%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.29%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 95.43%\n",
      "----------------------------------------\n",
      "Epoch 38/1000\n",
      "Training Loss: 0.0910\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.18%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.27%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.80%\n",
      "----------------------------------------\n",
      "Epoch 39/1000\n",
      "Training Loss: 0.0943\n",
      "Action 0 Accuracy: 99.26%\n",
      "Action 1 Accuracy: 99.70%\n",
      "Action 2 Accuracy: 99.19%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.25%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 94.54%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     45\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 47\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m num_batches\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    policy.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    if epoch %10 == 0:\n",
    "        batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n",
    "\n",
    "    action_correct = [0] * len(action_dims)\n",
    "    action_total = [0] * len(action_dims)\n",
    "    \n",
    "    random.shuffle(batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "        obs, actions, rewards, next_obs, prev_obs, dones, _, _ = batch\n",
    "        \n",
    "        actions = actions.permute(1, 0)\n",
    "\n",
    "        outputs = policy(obs)\n",
    "        optimizer.zero_grad()\n",
    "        split_logits = torch.split(outputs, action_dims, dim=-1)\n",
    "        \n",
    "        losses = []\n",
    "        # loss_weights = ([0,0,0,0,0,0,1]) # only train steering\n",
    "        loss_weights = ([1,1,1,1,1,1,10]) # train all actions\n",
    "        loss_weights = [x/sum(loss_weights) for x in loss_weights]\n",
    "        for i in range(actions.size(1)):\n",
    "            if loss_weights[i] ==0:\n",
    "                continue\n",
    "            loss_i = torch.nn.CrossEntropyLoss()(split_logits[i], actions[:,i])\n",
    "            losses.append(loss_weights[i] * loss_i)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            predicted = torch.argmax(split_logits[i], dim=1)\n",
    "            correct = (predicted == actions[:,i]).sum().item()\n",
    "            total = actions.size(0)\n",
    "            \n",
    "            action_correct[i] += correct\n",
    "            action_total[i] += total\n",
    "        \n",
    "        loss = sum(losses) #/ len(losses)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracies = [correct/(total or 1) * 100 for correct, total in zip(action_correct, action_total)]\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        print(f\"Action {i} Accuracy: {acc:.2f}%\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(),'policy_512_512_512_512_SiLU_3_statedict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
