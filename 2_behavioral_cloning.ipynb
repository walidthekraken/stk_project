{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154, [5, 2, 2, 2, 2, 2, 7])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "from pystk2_gymnasium import AgentSpec\n",
    "from stk_actor.replay_buffer import SACRolloutBuffer\n",
    "from stk_actor.wrappers import PreprocessObservationWrapper\n",
    "import torch\n",
    "\n",
    "class PolicyWrapper(torch.nn.Module):\n",
    "    def __init__(self, policy_stb, dropout):\n",
    "        super().__init__()\n",
    "        self.shared = policy_stb\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.shared.features_extractor(x)\n",
    "        x = self.shared.mlp_extractor.policy_net(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.shared.action_net(x)\n",
    "        return x\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    \"supertuxkart/flattened_multidiscrete-v0\", \n",
    "    n_envs=1, \n",
    "    wrapper_class=lambda x : (PreprocessObservationWrapper(x)), \n",
    "    env_kwargs={\n",
    "        'render_mode':None, 'agent':AgentSpec(use_ai=False, name=\"walid\"), 'difficulty':0,#'track':'abyss', #'num_kart':2, 'difficulty':0\n",
    "    }\n",
    ")\n",
    "vec_env.close()\n",
    "\n",
    "policy_stb = PPO('MlpPolicy', vec_env, policy_kwargs = dict(\n",
    "    net_arch=[512,512,512,512],\n",
    "    activation_fn=torch.nn.SiLU,\n",
    ")).policy\n",
    "\n",
    "obs_dim = vec_env.observation_space.shape[0]\n",
    "action_dims = [space.n for space in vec_env.action_space]\n",
    "\n",
    "device = 'mps'\n",
    "policy = PolicyWrapper(\n",
    "    policy_stb, 0.2\n",
    ").to(device)\n",
    "\n",
    "obs_dim, action_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_5166/1712889916.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n",
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_5166/1712889916.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches.extend([[torch.tensor(b).to(device) for b in batch] for batch in list(buffer2.get_batches(batch_size, start_step_id))])\n"
     ]
    }
   ],
   "source": [
    "import joblib, random\n",
    "from torch.optim import AdamW\n",
    "\n",
    "batch_size = 1024 * 8\n",
    "start_step_id = 18\n",
    "num_epochs = 1000\n",
    "device = 'mps'\n",
    "\n",
    "policy = policy.to(device)\n",
    "\n",
    "optimizer = AdamW(policy.parameters(), lr=2e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "buffer1 = joblib.load('all_tracks_buffer_steps_2mil')\n",
    "buffer2 = joblib.load('all_tracks_buffer_steps_1laps')\n",
    "\n",
    "batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n",
    "batches.extend([[torch.tensor(b).to(device) for b in batch] for batch in list(buffer2.get_batches(batch_size, start_step_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([154]), torch.Size([154]), torch.Size([1092612, 154]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_obs = torch.concatenate(\n",
    "    [\n",
    "        buffer1.observations[:buffer1.size],\n",
    "        buffer2.observations[:buffer2.size],\n",
    "    ], dim=0\n",
    ")\n",
    "mean = valid_obs.mean(dim=0).to(device)\n",
    "std = valid_obs.std(dim=0).to(device)\n",
    "mean.shape, std.shape, valid_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.dropout = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_5166/2488429409.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n",
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_5166/2488429409.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batches.extend([[torch.tensor(b).to(device) for b in batch] for batch in list(buffer2.get_batches(batch_size, start_step_id))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Training Loss: 1.4889\n",
      "Action 0 Accuracy: 97.23%\n",
      "Action 1 Accuracy: 99.20%\n",
      "Action 2 Accuracy: 98.25%\n",
      "Action 3 Accuracy: 99.20%\n",
      "Action 4 Accuracy: 98.41%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 42.64%\n",
      "----------------------------------------\n",
      "Epoch 2/1000\n",
      "Training Loss: 0.7159\n",
      "Action 0 Accuracy: 98.56%\n",
      "Action 1 Accuracy: 99.20%\n",
      "Action 2 Accuracy: 98.73%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 98.98%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 59.57%\n",
      "----------------------------------------\n",
      "Epoch 3/1000\n",
      "Training Loss: 0.6344\n",
      "Action 0 Accuracy: 98.58%\n",
      "Action 1 Accuracy: 99.21%\n",
      "Action 2 Accuracy: 98.74%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.04%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 64.02%\n",
      "----------------------------------------\n",
      "Epoch 4/1000\n",
      "Training Loss: 0.6102\n",
      "Action 0 Accuracy: 98.59%\n",
      "Action 1 Accuracy: 99.21%\n",
      "Action 2 Accuracy: 98.73%\n",
      "Action 3 Accuracy: 99.96%\n",
      "Action 4 Accuracy: 99.05%\n",
      "Action 5 Accuracy: 100.00%\n",
      "Action 6 Accuracy: 65.38%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 54\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m num_batches\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    policy.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    if epoch %10 == 0:\n",
    "        batches = [[torch.tensor(b).to(device) for b in batch] for batch in list(buffer1.get_batches(batch_size, start_step_id))]\n",
    "        batches.extend([[torch.tensor(b).to(device) for b in batch] for batch in list(buffer2.get_batches(batch_size, start_step_id))])\n",
    "\n",
    "    action_correct = [0] * len(action_dims)\n",
    "    action_total = [0] * len(action_dims)\n",
    "    \n",
    "    random.shuffle(batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "        obs, actions, rewards, next_obs, prev_obs, dones, _, _ = batch\n",
    "        obs = obs \n",
    "        # mean = obs.mean(dim=1, keepdim=True)\n",
    "        # std = obs.std(dim=1, keepdim=True)\n",
    "        # obs = (obs - mean.unsqueeze(0)) / (std.unsqueeze(0) + 1e-8)\n",
    "        obs = obs #+ torch.randn_like(obs) * 0.02\n",
    "\n",
    "        actions = actions.permute(1, 0)\n",
    "\n",
    "        outputs = policy(obs)\n",
    "        optimizer.zero_grad()\n",
    "        split_logits = torch.split(outputs, action_dims, dim=-1)\n",
    "        \n",
    "        losses = []\n",
    "        # loss_weights = ([0,0,0,0,0,0,1]) # only train steering\n",
    "        loss_weights = ([1,1,1,1,1,1,10]) # train all actions\n",
    "        loss_weights = [x/sum(loss_weights) for x in loss_weights]\n",
    "        for i in range(actions.size(1)):\n",
    "            if loss_weights[i] ==0:\n",
    "                continue\n",
    "            loss_i = torch.nn.CrossEntropyLoss()(split_logits[i], actions[:,i])\n",
    "            losses.append(loss_weights[i] * loss_i)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            predicted = torch.argmax(split_logits[i], dim=1)\n",
    "            correct = (predicted == actions[:,i]).sum().item()\n",
    "            total = actions.size(0)\n",
    "            \n",
    "            action_correct[i] += correct\n",
    "            action_total[i] += total\n",
    "\n",
    "            \n",
    "        loss = sum(losses)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracies = [correct/(total or 1) * 100 for correct, total in zip(action_correct, action_total)]\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        print(f\"Action {i} Accuracy: {acc:.2f}%\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(),'policy_notnorm_512_512_512_512_SiLU_statedict')\n",
    "torch.save(mean,'buffer_mean')\n",
    "torch.save(std,'buffer_std')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
