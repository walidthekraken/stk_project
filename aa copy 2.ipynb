{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making 42 environments\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_33918/2491321862.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mean = torch.load(path+f'{agent}/buffer_mean', map_location='cpu')\n",
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_33918/2491321862.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.std = torch.load(path+f'{agent}/buffer_std', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "0 (0, 'abyss')\n",
      "1 (1, 'black_forest')\n",
      "2 (2, 'candela_city')\n",
      "3 (3, 'cocoa_temple')\n",
      "4 (4, 'cornfield_crossing')\n",
      "5 (5, 'fortmagma')\n",
      "6 (6, 'gran_paradiso_island')\n",
      "7 (7, 'hacienda')\n",
      "8 (8, 'lighthouse')\n",
      "9 (9, 'mines')\n",
      "10 (10, 'minigolf')\n",
      "11 (11, 'olivermath')\n",
      "12 (12, 'ravenbridge_mansion')\n",
      "13 (13, 'sandtrack')\n",
      "14 (14, 'scotland')\n",
      "15 (15, 'snowmountain')\n",
      "16 (16, 'snowtuxpeak')\n",
      "17 (17, 'stk_enterprise')\n",
      "18 (18, 'volcano_island')\n",
      "19 (19, 'xr591')\n",
      "20 (20, 'zengarden')\n",
      "21 (0, 'abyss')\n",
      "22 (1, 'black_forest')\n",
      "23 (2, 'candela_city')\n",
      "24 (3, 'cocoa_temple')\n",
      "25 (4, 'cornfield_crossing')\n",
      "26 (5, 'fortmagma')\n",
      "27 (6, 'gran_paradiso_island')\n",
      "28 (7, 'hacienda')\n",
      "29 (8, 'lighthouse')\n",
      "30 (9, 'mines')\n",
      "31 (10, 'minigolf')\n",
      "32 (11, 'olivermath')\n",
      "33 (12, 'ravenbridge_mansion')\n",
      "34 (13, 'sandtrack')\n",
      "35 (14, 'scotland')\n",
      "36 (15, 'snowmountain')\n",
      "37 (16, 'snowtuxpeak')\n",
      "38 (17, 'stk_enterprise')\n",
      "39 (18, 'volcano_island')\n",
      "40 (19, 'xr591')\n",
      "41 (20, 'zengarden')\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/wsyz4crx22bg_7tpsgbw3tzw0000gn/T/ipykernel_33918/2491321862.py:327: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unified_policy.load_state_dict(torch.load(filename, map_location='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stk_actor.wrappers import StuckStopWrapper\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path = 'stk_actor/trained_agents/'\n",
    "agent = 'normed_a2c_num5_best'\n",
    "\n",
    "class PreprocessObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        A Gym wrapper to preprocess mixed observation space (continuous + discrete)\n",
    "        into a flat tensor.\n",
    "        \n",
    "        Args:\n",
    "            env: The Gym environment to wrap.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.observation_space = self._get_flat_observation_space(env.observation_space)\n",
    "        self.mean = torch.load(path+f'{agent}/buffer_mean', map_location='cpu')\n",
    "        self.std = torch.load(path+f'{agent}/buffer_std', map_location='cpu')\n",
    "\n",
    "    def _get_flat_observation_space(self, observation_space):\n",
    "        \"\"\"\n",
    "        Create a flat observation space based on the original observation space.\n",
    "        \n",
    "        Args:\n",
    "            observation_space: Original observation space with 'continuous' and 'discrete' components.\n",
    "        \n",
    "        Returns:\n",
    "            A flattened observation space.\n",
    "        \"\"\"\n",
    "        continuous_dim = observation_space['continuous'].shape[0]\n",
    "        discrete_dims = sum(space.n for space in observation_space['discrete'])\n",
    "        flat_dim = continuous_dim + discrete_dims\n",
    "        return gym.spaces.Box(low=-float('inf'), high=float('inf'), shape=(flat_dim,), dtype=float)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \"\"\"\n",
    "        Process the observation into a flat tensor.\n",
    "        \n",
    "        Args:\n",
    "            obs: The raw observation from the environment.\n",
    "        \n",
    "        Returns:\n",
    "            A preprocessed flat tensor.\n",
    "        \"\"\"\n",
    "        continuous_obs, discrete_obs = obs['continuous'], obs['discrete']\n",
    "        continuous_tensor = torch.FloatTensor(continuous_obs)\n",
    "        \n",
    "        discrete_tensors = [\n",
    "            F.one_hot(torch.tensor(x), num_classes=num_classes.n).float()\n",
    "            for x, num_classes in zip(discrete_obs, self.env.observation_space['discrete'])\n",
    "        ]\n",
    "        \n",
    "        flat_tensor = torch.cat([continuous_tensor] + discrete_tensors)\n",
    "        normed_flat_tensor = (flat_tensor - self.mean) / (self.std + 1e-8)\n",
    "        return normed_flat_tensor\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class SkipFirstNStepsWrapper(Wrapper):\n",
    "    def __init__(self, env, n):\n",
    "        super().__init__(env)\n",
    "        self.n = n\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Reset the environment\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        # Skip the first n steps\n",
    "        for _ in range(self.n):\n",
    "            obs, _, done, truncated, info = self.env.step(self.env.action_space.sample())\n",
    "            if done or truncated:\n",
    "                obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from typing import Dict, List, Tuple, Union, Type\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "def get_device(device: Union[torch.device, str] = \"auto\") -> torch.device:\n",
    "    if device == \"auto\":\n",
    "        device = \"cuda\"\n",
    "    device = torch.device(device)\n",
    "    if device.type == torch.device(\"cuda\").type and not torch.cuda.is_available():\n",
    "        return torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "class BaseFeaturesExtractor(nn.Module):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 0) -> None:\n",
    "        super().__init__()\n",
    "        assert features_dim > 0\n",
    "        self._observation_space = observation_space\n",
    "        self._features_dim = features_dim\n",
    "    @property\n",
    "    def features_dim(self) -> int:\n",
    "        return self._features_dim\n",
    "\n",
    "def get_flattened_obs_dim(observation_space: spaces.Space) -> int:\n",
    "    if isinstance(observation_space, spaces.MultiDiscrete):\n",
    "        return sum(observation_space.nvec)\n",
    "    else:\n",
    "        return spaces.utils.flatdim(observation_space)\n",
    "\n",
    "class FlattenExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space) -> None:\n",
    "        super().__init__(observation_space, get_flattened_obs_dim(observation_space))\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.flatten(observations)\n",
    "    \n",
    "class MlpExtractor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim: int,\n",
    "        net_arch: Union[List[int], Dict[str, List[int]]],\n",
    "        activation_fn: Type[nn.Module],\n",
    "        device: Union[torch.device, str] = \"auto\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # device = torch.get_device(device)\n",
    "        policy_net: List[nn.Module] = []\n",
    "        value_net: List[nn.Module] = []\n",
    "        last_layer_dim_pi = feature_dim\n",
    "        last_layer_dim_vf = feature_dim\n",
    "\n",
    "        if isinstance(net_arch, dict):\n",
    "            pi_layers_dims = net_arch.get(\"pi\", []) \n",
    "            vf_layers_dims = net_arch.get(\"vf\", []) \n",
    "        else:\n",
    "            pi_layers_dims = vf_layers_dims = net_arch\n",
    "        for curr_layer_dim in pi_layers_dims:\n",
    "            policy_net.append(nn.Linear(last_layer_dim_pi, curr_layer_dim))\n",
    "            policy_net.append(activation_fn())\n",
    "            last_layer_dim_pi = curr_layer_dim\n",
    "        for curr_layer_dim in vf_layers_dims:\n",
    "            value_net.append(nn.Linear(last_layer_dim_vf, curr_layer_dim))\n",
    "            value_net.append(activation_fn())\n",
    "            last_layer_dim_vf = curr_layer_dim\n",
    "\n",
    "        self.latent_dim_pi = last_layer_dim_pi\n",
    "        self.latent_dim_vf = last_layer_dim_vf\n",
    "        self.policy_net = nn.Sequential(*policy_net)#.to(device)\n",
    "        self.value_net = nn.Sequential(*value_net)#.to(device)\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        :return: latent_policy, latent_value of the specified network.\n",
    "            If all layers are shared, then ``latent_policy == latent_value``\n",
    "        \"\"\"\n",
    "        return self.forward_actor(features), self.forward_critic(features)\n",
    "\n",
    "    def forward_actor(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "    \n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, observation_space, action_dims, net_arch, activation_fn,):\n",
    "        super().__init__()\n",
    "        self.features_extractor = FlattenExtractor(observation_space)\n",
    "        self.pi_features_extractor = self.features_extractor\n",
    "        self.vf_features_extractor = self.features_extractor\n",
    "        self.mlp_extractor = MlpExtractor(\n",
    "            self.features_extractor.features_dim,\n",
    "            net_arch=net_arch,\n",
    "            activation_fn=activation_fn,\n",
    "        )\n",
    "        self.action_net = nn.Linear(net_arch[-1], sum(action_dims))\n",
    "        self.value_net = nn.Linear(net_arch[-1], 1)\n",
    "\n",
    "\n",
    "class UnifiedSACPolicy(nn.Module):\n",
    "    def __init__(self, observation_space, action_dims, net_arch, activation_fn):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared = Policy(\n",
    "            observation_space,\n",
    "            action_dims,\n",
    "            net_arch=net_arch,\n",
    "            activation_fn=activation_fn\n",
    "        )\n",
    "        self.action_dims = action_dims\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.shared.features_extractor(x)\n",
    "        x = self.shared.mlp_extractor.policy_net(x)\n",
    "        x = self.shared.action_net(x)\n",
    "        return x\n",
    "    \n",
    "    def sample(self, x, deterministic=False):\n",
    "        logits = self.forward(x)\n",
    "        \n",
    "        # Split logits for each action dimension\n",
    "        split_logits = torch.split(logits, self.action_dims, dim=-1)\n",
    "        \n",
    "        actions = []\n",
    "        log_probs = []\n",
    "        probs = []\n",
    "        \n",
    "        for logit in split_logits:\n",
    "            distribution = Categorical(logits=logit)\n",
    "            if deterministic:\n",
    "                action = torch.argmax(logit, dim=-1)\n",
    "            else:\n",
    "                action = distribution.sample()\n",
    "            \n",
    "            log_prob = distribution.log_prob(action)\n",
    "            prob = F.softmax(logit, dim=-1)\n",
    "            \n",
    "            actions.append(action)\n",
    "            log_probs.append(log_prob)\n",
    "            probs.append(prob)\n",
    "        \n",
    "        return (\n",
    "            torch.stack(actions),\n",
    "            torch.stack(log_probs),\n",
    "            probs\n",
    "        )\n",
    "    \n",
    "#policy = torch.load('policy_512_512_512_512_SiLU_3_statedict', map_location='cuda')\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "from pystk2_gymnasium import AgentSpec\n",
    "from bbrl.agents.gymnasium import ParallelGymAgent, make_env\n",
    "from functools import partial\n",
    "\n",
    "tracks = [\n",
    "    'abyss',\n",
    "    'black_forest',\n",
    "    'candela_city',\n",
    "    'cocoa_temple',\n",
    "    'cornfield_crossing',\n",
    "    'fortmagma',\n",
    "    'gran_paradiso_island',\n",
    "    'hacienda',\n",
    "    'lighthouse',\n",
    "    'mines',\n",
    "    'minigolf',\n",
    "    'olivermath',\n",
    "    'ravenbridge_mansion',\n",
    "    'sandtrack',\n",
    "    'scotland',\n",
    "    'snowmountain',\n",
    "    'snowtuxpeak',\n",
    "    'stk_enterprise',\n",
    "    'volcano_island',\n",
    "    'xr591',\n",
    "    'zengarden',\n",
    "\n",
    "# # #   ==================   #\n",
    "\n",
    "#     'fortmagma',\n",
    "#     'ravenbridge_mansion',\n",
    "#     'snowmountain',\n",
    "#     'cocoa_temple',\n",
    "#     'sandtrack',    \n",
    "#     'scotland', \n",
    "#     'stk_enterprise',\n",
    "#     'volcano_island', # 1104\n",
    "#     'xr591', # 864   \n",
    "]\n",
    "\n",
    "# karts = [4,12]\n",
    "karts = [3,12]\n",
    "n_envs = len(tracks)*len(karts)\n",
    "\n",
    "print('making', n_envs, 'environments')\n",
    "vec_env = make_vec_env(\n",
    "    \"supertuxkart/flattened_multidiscrete-v0\",\n",
    "    # seed=12,\n",
    "    n_envs=n_envs, \n",
    "    wrapper_class=lambda x : (\n",
    "        SkipFirstNStepsWrapper(\n",
    "            StuckStopWrapper(\n",
    "                PreprocessObservationWrapper(x),\n",
    "                n=128,\n",
    "            ), \n",
    "            n=19,\n",
    "        )\n",
    "    ), \n",
    "    env_kwargs={\n",
    "    'render_mode':None, 'agent':AgentSpec(use_ai=False, name=\"walid\"), #'track':'minigolf', \n",
    "    'laps':1,\n",
    "    'difficulty':2, \n",
    "    'num_kart':12, #'difficulty':0\n",
    "})\n",
    "\n",
    "ix = 0\n",
    "for num_kart in enumerate(karts):\n",
    "    for track in enumerate(tracks):\n",
    "        venv = vec_env.envs[ix]\n",
    "        venv.env.default_track = track\n",
    "        venv.env.num_kart = num_kart\n",
    "        print(ix, track, )\n",
    "        ix+=1\n",
    "\n",
    "\n",
    "\n",
    "net_arch=[1024,1024,1024]\n",
    "activation_fn=torch.nn.Tanh\n",
    "# filename = 'policy_normed_1024_1024_1024_Tanh_statedict_2'\n",
    "filename = path+f'{agent}/statedict'\n",
    "\n",
    "action_dims = [space.n for space in vec_env.action_space]\n",
    "unified_policy = UnifiedSACPolicy(\n",
    "    vec_env.observation_space, \n",
    "    action_dims, \n",
    "    net_arch=net_arch, \n",
    "    activation_fn=activation_fn\n",
    ")\n",
    "unified_policy.load_state_dict(torch.load(filename, map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "Using cpu device\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "DOING 5 1000000\n",
      "Logging to ./outputs/A2C_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44c9a5fd8624eb897a621eea12b1c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 9   |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 21  |\n",
      "|    total_timesteps | 210 |\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 16       |\n",
      "|    iterations         | 2        |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 420      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | 0.428    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1        |\n",
      "|    policy_loss        | -0.0792  |\n",
      "|    value_loss         | 151      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 3        |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 630      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.184   |\n",
      "|    explained_variance | 0.397    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2        |\n",
      "|    policy_loss        | -0.00817 |\n",
      "|    value_loss         | 107      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 26       |\n",
      "|    iterations         | 4        |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 840      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.216   |\n",
      "|    explained_variance | 0.598    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3        |\n",
      "|    policy_loss        | -0.144   |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 30       |\n",
      "|    iterations         | 5        |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 1050     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.183   |\n",
      "|    explained_variance | -0.109   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4        |\n",
      "|    policy_loss        | -0.0129  |\n",
      "|    value_loss         | 7        |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 33       |\n",
      "|    iterations         | 6        |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 1260     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.182   |\n",
      "|    explained_variance | -0.18    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5        |\n",
      "|    policy_loss        | -0.0222  |\n",
      "|    value_loss         | 6.97     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 7        |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 1470     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | -0.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6        |\n",
      "|    policy_loss        | 0.0358   |\n",
      "|    value_loss         | 9.33     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 8        |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 1680     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.257   |\n",
      "|    explained_variance | -0.0343  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7        |\n",
      "|    policy_loss        | -0.0219  |\n",
      "|    value_loss         | 8.27     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 9        |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 1890     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.246   |\n",
      "|    explained_variance | 0.179    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8        |\n",
      "|    policy_loss        | 0.0822   |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 10       |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 2100     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.228   |\n",
      "|    explained_variance | 0.11     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9        |\n",
      "|    policy_loss        | 0.0734   |\n",
      "|    value_loss         | 35.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 11       |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 2310     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.279   |\n",
      "|    explained_variance | 0.215    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10       |\n",
      "|    policy_loss        | 0.0285   |\n",
      "|    value_loss         | 31.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 12       |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 2520     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.219   |\n",
      "|    explained_variance | 0.439    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11       |\n",
      "|    policy_loss        | 0.0241   |\n",
      "|    value_loss         | 38       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 13       |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 2730     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.249   |\n",
      "|    explained_variance | -5.16    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12       |\n",
      "|    policy_loss        | -0.0354  |\n",
      "|    value_loss         | 146      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 14       |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 2940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.268   |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13       |\n",
      "|    policy_loss        | 0.00771  |\n",
      "|    value_loss         | 36.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15       |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 3150     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.264   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14       |\n",
      "|    policy_loss        | 0.077    |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16       |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 3360     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.188   |\n",
      "|    explained_variance | -0.628   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15       |\n",
      "|    policy_loss        | 0.0265   |\n",
      "|    value_loss         | 49.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 17       |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 3570     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.211   |\n",
      "|    explained_variance | 0.775    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16       |\n",
      "|    policy_loss        | 0.0543   |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 18       |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 3780     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.172   |\n",
      "|    explained_variance | 0.85     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17       |\n",
      "|    policy_loss        | 0.00149  |\n",
      "|    value_loss         | 9.26     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 19       |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 3990     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.18    |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18       |\n",
      "|    policy_loss        | 0.0164   |\n",
      "|    value_loss         | 6.41     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 20       |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 4200     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | 0.859    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19       |\n",
      "|    policy_loss        | -0.00675 |\n",
      "|    value_loss         | 13.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 21       |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 4410     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.214   |\n",
      "|    explained_variance | 0.89     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20       |\n",
      "|    policy_loss        | 0.0121   |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 22       |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 4620     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.232   |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21       |\n",
      "|    policy_loss        | 0.121    |\n",
      "|    value_loss         | 6.49     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 23       |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 4830     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.282   |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22       |\n",
      "|    policy_loss        | -0.00106 |\n",
      "|    value_loss         | 7.62     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 24       |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 5040     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.295   |\n",
      "|    explained_variance | 0.859    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23       |\n",
      "|    policy_loss        | 0.0147   |\n",
      "|    value_loss         | 33.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 25       |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 5250     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.262   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24       |\n",
      "|    policy_loss        | -0.00291 |\n",
      "|    value_loss         | 5.18     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 26       |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 5460     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.241   |\n",
      "|    explained_variance | 0.957    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25       |\n",
      "|    policy_loss        | 0.066    |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 27       |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 5670     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.21    |\n",
      "|    explained_variance | 0.963    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26       |\n",
      "|    policy_loss        | 0.00209  |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 28       |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 5880     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.2     |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27       |\n",
      "|    policy_loss        | 0.161    |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 29       |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 6090     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.227   |\n",
      "|    explained_variance | 0.962    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28       |\n",
      "|    policy_loss        | 0.0481   |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 30       |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 6300     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.174   |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29       |\n",
      "|    policy_loss        | -0.0274  |\n",
      "|    value_loss         | 20.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 31       |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 6510     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.235   |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30       |\n",
      "|    policy_loss        | -0.0066  |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 32       |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 6720     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.248   |\n",
      "|    explained_variance | 0.932    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31       |\n",
      "|    policy_loss        | -0.00429 |\n",
      "|    value_loss         | 29       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 33       |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.275   |\n",
      "|    explained_variance | 0.965    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32       |\n",
      "|    policy_loss        | 0.0298   |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 34       |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 7140     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.314   |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33       |\n",
      "|    policy_loss        | 0.0484   |\n",
      "|    value_loss         | 41.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 35       |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 7350     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.369   |\n",
      "|    explained_variance | 0.947    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34       |\n",
      "|    policy_loss        | -0.0631  |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 36       |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 7560     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.291   |\n",
      "|    explained_variance | 0.893    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35       |\n",
      "|    policy_loss        | -0.0229  |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 37       |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 7770     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.295   |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36       |\n",
      "|    policy_loss        | 0.00636  |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 38       |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 7980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.245   |\n",
      "|    explained_variance | 0.934    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37       |\n",
      "|    policy_loss        | -0.0449  |\n",
      "|    value_loss         | 36.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 39       |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 8190     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.229   |\n",
      "|    explained_variance | 0.864    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38       |\n",
      "|    policy_loss        | -0.00606 |\n",
      "|    value_loss         | 70.2     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 40       |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 8400     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.322   |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39       |\n",
      "|    policy_loss        | -0.0357  |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 41       |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 8610     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.312   |\n",
      "|    explained_variance | 0.775    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40       |\n",
      "|    policy_loss        | -0.00786 |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 42       |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 8820     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.304   |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41       |\n",
      "|    policy_loss        | -0.00146 |\n",
      "|    value_loss         | 46.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 43       |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 9030     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.267   |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42       |\n",
      "|    policy_loss        | 0.0134   |\n",
      "|    value_loss         | 92.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 44       |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 9240     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.319   |\n",
      "|    explained_variance | 0.91     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43       |\n",
      "|    policy_loss        | 0.0482   |\n",
      "|    value_loss         | 53.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 45       |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 9450     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.301   |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44       |\n",
      "|    policy_loss        | -0.104   |\n",
      "|    value_loss         | 35.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 46       |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 9660     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.278   |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45       |\n",
      "|    policy_loss        | -0.0149  |\n",
      "|    value_loss         | 44.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 47       |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 9870     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.322   |\n",
      "|    explained_variance | 0.924    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46       |\n",
      "|    policy_loss        | -0.0167  |\n",
      "|    value_loss         | 44.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 48       |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 10080    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | 0.924    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47       |\n",
      "|    policy_loss        | 0.0129   |\n",
      "|    value_loss         | 40.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 49       |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 10290    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.263   |\n",
      "|    explained_variance | 0.965    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48       |\n",
      "|    policy_loss        | 0.0296   |\n",
      "|    value_loss         | 19.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 50       |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.314   |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 49       |\n",
      "|    policy_loss        | 0.0241   |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 51       |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 10710    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.293   |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50       |\n",
      "|    policy_loss        | -0.019   |\n",
      "|    value_loss         | 88.2     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "\n",
    "steps = [(\n",
    "    # 1024*8,\n",
    "    5*n_envs,\n",
    "    1_000_000,\n",
    ")]\n",
    "for n_steps, total_timesteps in steps:\n",
    "    # model = PPO(\n",
    "    #     \"MlpPolicy\", \n",
    "    #     vec_env, \n",
    "    #     verbose=1, \n",
    "    #     policy_kwargs = dict(net_arch=net_arch, activation_fn=activation_fn,),\n",
    "    #     device='cpu',\n",
    "    #     learning_rate=0.0001,\n",
    "    #     batch_size=128,\n",
    "    #     n_epochs=100,\n",
    "    #     n_steps=n_steps,\n",
    "    #     tensorboard_log=\"./outputs/\",\n",
    "    #     # ent_coef=0.001,\n",
    "    #     clip_range=0.2,\n",
    "    # )\n",
    "    model = A2C(\n",
    "        \"MlpPolicy\", \n",
    "        vec_env, \n",
    "        verbose=1, \n",
    "        policy_kwargs = dict(net_arch=net_arch, activation_fn=activation_fn,),\n",
    "        device='cpu',\n",
    "        # learning_rate=0.001,\n",
    "        n_steps=n_steps,\n",
    "        tensorboard_log=\"./outputs/\",\n",
    "        use_rms_prop=False,\n",
    "        normalize_advantage=True,\n",
    "    )\n",
    "    print('DOING', n_steps, total_timesteps)\n",
    "    model.policy.load_state_dict(unified_policy.shared.state_dict())\n",
    "    model.learn(total_timesteps=total_timesteps, progress_bar=True, log_interval=1)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_a2c_2048'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(f'final_a2c_{n_steps}')\n",
    "f'final_a2c_{n_steps}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
